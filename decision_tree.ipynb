{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import log_loss, roc_curve, auc, RocCurveDisplay,  silhouette_score, classification_report, accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.chdir(\"/Users/yj.noh/Documents/GitHub/prj_on_boarding\")\n",
    "print(os.getcwd())\n",
    "plt.rcParams['font.family'] = 'AppleGothic'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/yj.noh/Desktop/new_on_boarding_data.csv\", encoding = \"cp949\")\n",
    "print(df.shape) # 16,134\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 친구추천 아닌 사람만! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_filter = df[((df['day_cnt'].notnull()) & (df['delivery_method'] == 'BIKE') & (df['is_recom'] == 0))]\n",
    "#data_filter = df[((df['day_cnt'].notnull()) & (df['delivery_method'] == 'BIKE'))]\n",
    "\n",
    "df =  df[((df['active_days'].notnull()) & (df['is_recom'] == 0))]\n",
    "print(df.isna().sum())\n",
    "print(df.shape)  # 10,245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['outcome'].value_counts()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vars = ['birth', 'delivery_method', 'insurance_type', 'is_recom', 'gender']\n",
    "num_vars = ['active_days', 'avg_daily_delivery', 'avg_distance', 'avg_fee', 'avg_distance_1_to_3', 'avg_fee_1_to_3', 'join_period', 'from_join_to_first_able', 'from_first_able_to_start']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = plasma, coolwarm, magma, BuGn, Dark2 \n",
    "def plot_numeric (data, numeric_vars, outcome):\n",
    "    \n",
    "    os.makedirs('graphs_all/', exist_ok = True)\n",
    "    \n",
    "    palette = 'coolwarm'\n",
    "    \n",
    "    mapping = {0 : '미이탈', 1 : '이탈'}\n",
    "    data[outcome] = data[outcome].replace(mapping)\n",
    "    \n",
    "    for num_var in numeric_vars:\n",
    "        fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "        fig.suptitle(f'{num_var} 분포', fontsize = 12)\n",
    "    \n",
    "        # Boxplot\n",
    "        sns.boxplot(ax=axs[0], x= outcome, y=num_var, data= data, palette = palette)\n",
    "        axs[0].set_title('Boxplot')\n",
    "    \n",
    "        # Violinplot\n",
    "        sns.violinplot(ax=axs[1], x = outcome, y = num_var, data = data, palette = palette)\n",
    "        axs[1].set_title('Violinplot')\n",
    "        \n",
    "        # KDE plot\n",
    "        sns.kdeplot(ax=axs[2], data = data, x = num_var, hue = outcome, fill = True, common_norm = False, palette = palette, alpha=.5, linewidth=0)\n",
    "        axs[2].set_title('Density plot')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(top=0.8) # title 공간 확보\n",
    "        \n",
    "        fig.savefig(f'graphs_all/{num_var}_distributions.png')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric(df, num_vars, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# sns.boxplot(data=data_filter, x='outcome', y='avg_cnt')\n",
    "# plt.title(\"outcome 별 일평균수행처리건수\")\n",
    "# plt.savefig(\"prj_on_boarding/boxplot1.png\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.boxplot(data=data_filter, x='outcome', y='day_cnt')\n",
    "# plt.title(\"outcome 별 수행일수\")\n",
    "# plt.savefig(\"prj_on_boarding/boxplot2.png\")\n",
    "# plt.show()\n",
    "\n",
    "# # day_cnt\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.violinplot(x='outcome', y='day_cnt', data=data_filtered_both)\n",
    "# plt.title('Distribution of day_cnt by outcome')\n",
    "# plt.show()\n",
    "\n",
    "# # avg_cnt\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.violinplot(x='outcome', y='avg_cnt', data=data_filtered_both)\n",
    "# plt.title('Distribution of avg_cnt by outcome')\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 category 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category(data, category_vars, outcome) : \n",
    "    \n",
    "    # outcome 값 변경\n",
    "    mapping  = {0 : '미이탈', 1 : '이탈'}\n",
    "    data[outcome] = data[outcome].replace(mapping)\n",
    "    \n",
    "    palette = 'coolwarm'\n",
    "    \n",
    "    # 저장할 디렉토리 생성\n",
    "    os.makedirs('graphs_all', exist_ok = True)\n",
    "    \n",
    "    for cat_var in category_vars : \n",
    "        plt.figure(figsize = (12,4))\n",
    "        ax = sns.countplot(x=cat_var, hue=outcome, data=data, palette=palette)\n",
    "        plt.title(f'이탈여부에 따른 {cat_var} 분포')\n",
    "        plt.ylabel('개수')\n",
    "        plt.legend(title=outcome, loc='upper right')\n",
    "        plt.xticks(fontsize=8)  # x축 글씨 조정\n",
    "        \n",
    "        # 각 막대에 데이터 레이블 추가\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{int(p.get_height())}',  # 높이 값(즉, 개수)을 얻어 텍스트로 설정\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),  # 텍스트 위치 설정\n",
    "                        ha='center',  # 가로 정렬(center)\n",
    "                        va='center',  # 세로 정렬(center)\n",
    "                        xytext=(0, 10),  # 텍스트 오프셋(위쪽으로 약간 이동)\n",
    "                        textcoords='offset points',  # 어떤 종류의 오프셋을 사용할지 정의\n",
    "                        fontsize=10)  # 글꼴 크기\n",
    "        \n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'graphs_all/{cat_var}_distributions.png')\n",
    "        plt.show()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_category(df, category_vars, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['delivery_method'].value_counts()) # bike, p_bicycles, car, g_bicycles, walk, throttle_bicycles, kickboard "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BIKE만 대상으로 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bike = df[(df['delivery_method'] == 'WALK')]\n",
    "\n",
    "print(data_bike.shape)\n",
    "print(data_bike['delivery_method'].value_counts()) \n",
    "\n",
    "#data_bike = df[df['delivery_method'].isin(['PAS_BICYCLES', 'GENERAL_BICYCLES', 'THROTTLE_BICYCLES', 'KICKBOARD'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1.numeric - outlier 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이탈 값 되돌리기\n",
    "mapping  = { '미이탈' : 0 ,  '이탈' : 1}\n",
    "data_bike['outcome'] = data_bike['outcome'].replace(mapping)\n",
    "\n",
    "# outlier 제거  - outcome 별로 나눠서 \n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df.groupby('outcome')[column].quantile(0.25)\n",
    "    Q3 = df.groupby('outcome')[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    return df[df.apply(lambda x: (x[column] >= lower_bound[x['outcome']]) & \n",
    "                                 (x[column] <= upper_bound[x['outcome']]), axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'avg_cnt'와 'day_cnt'에 대한 아웃라이어 제거\n",
    "data_filtered_avg = remove_outliers(data_bike, 'active_days')\n",
    "data_filtered_both = remove_outliers(data_bike, 'avg_daily_delivery')\n",
    "\n",
    "print(data_filtered_both.shape)  \n",
    "print(data_filtered_both['outcome'].value_counts())\n",
    "\n",
    "data_filtered_both.to_excel('data_filtered_both.xlsx', index=False, engine='openpyxl') # 3,393 / 2,255, 1,138 -> 1,782/ 1203, 579"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2 그래프 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = plasma, coolwarm, magma, BuGn, Dark2 \n",
    "def plot_numeric (data, numeric_vars, outcome):\n",
    "    \n",
    "    os.makedirs('graph_walk', exist_ok = True)\n",
    "    \n",
    "    palette = 'coolwarm'\n",
    "    \n",
    "    for num_var in numeric_vars:\n",
    "        fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "        fig.suptitle(f'{num_var} 분포', fontsize = 12)\n",
    "    \n",
    "        # Boxplot\n",
    "        sns.boxplot(ax=axs[0], x= outcome, y=num_var, data= data, palette = palette)\n",
    "        axs[0].set_title('Boxplot')\n",
    "    \n",
    "        # Violinplot\n",
    "        sns.violinplot(ax=axs[1], x = outcome, y = num_var, data = data, palette = palette)\n",
    "        axs[1].set_title('Violinplot')\n",
    "        \n",
    "        # KDE plot\n",
    "        sns.kdeplot(ax=axs[2], data = data, x = num_var, hue = outcome, fill = True, common_norm = False, palette = palette, alpha=.5, linewidth=0)\n",
    "        axs[2].set_title('Density plot')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(top=0.8) # title 공간 확보\n",
    "        \n",
    "        fig.savefig(f'graph_walk/{num_var}_distributions_bike.png')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    \n",
    "def plot_category(data, category_vars, outcome) : \n",
    "    \n",
    "    # outcome 값 변경\n",
    "    mapping  = {0 : '미이탈', 1 : '이탈'}\n",
    "    data[outcome] = data[outcome].replace(mapping)\n",
    "    \n",
    "    palette = 'coolwarm'\n",
    "    \n",
    "    for cat_var in category_vars : \n",
    "        plt.figure(figsize = (12,4))\n",
    "        ax = sns.countplot(x=cat_var, hue = 'outcome', data = data, palette = palette)\n",
    "        plt.title(f'이탈여부에 따른 {cat_var} 분포')\n",
    "        plt.ylabel('개수')\n",
    "        plt.legend(title=outcome, loc='upper right')\n",
    "        plt.xticks(fontsize=8)  # x축 글씨 조정\n",
    "        \n",
    "        # 각 막대에 데이터 레이블 추가\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{int(p.get_height())}',  # 높이 값(즉, 개수)을 얻어 텍스트로 설정\n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()),  # 텍스트 위치 설정\n",
    "                        ha='center',  # 가로 정렬(center)\n",
    "                        va='center',  # 세로 정렬(center)\n",
    "                        xytext=(0, 10),  # 텍스트 오프셋(위쪽으로 약간 이동)\n",
    "                        textcoords='offset points',  # 어떤 종류의 오프셋을 사용할지 정의\n",
    "                        fontsize=10)  # 글꼴 크기\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'graph_walk/{cat_var}_distributions_bike.png')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric(data_filtered_both, num_vars, 'outcome')\n",
    "plot_category(data_filtered_both, category_vars, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_filtered_both = df\n",
    "\n",
    "# 이탈 값 되돌리기\n",
    "mapping  = { '미이탈' : 0 ,  '이탈' : 1}\n",
    "data_filtered_both['outcome'] = data_filtered_both['outcome'].replace(mapping)\n",
    "\n",
    "# 데이터 필터링\n",
    "X_test_0 = data_filtered_both[data_filtered_both['outcome'] == 0]\n",
    "X_test_1 = data_filtered_both[data_filtered_both['outcome'] == 1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# KDE plot\n",
    "# `cbar=True`를 추가하여 컬러 바를 그래프에 추가\n",
    "# `thresh`를 설정하여 밀도가 낮은 영역을 숨기기\n",
    "sns.kdeplot(data=X_test_0, x='active_days', y='avg_daily_delivery', cmap='Blues', shade=True, alpha=0.5, cbar=True, thresh=0.05)\n",
    "sns.kdeplot(data=X_test_1, x='active_days', y='avg_daily_delivery', cmap='Oranges', shade=True, alpha=0.5, cbar=True, thresh=0.05)\n",
    "\n",
    "plt.xlabel('수행일자')\n",
    "plt.ylabel('일평균수행건수')\n",
    "plt.title('Density plot of active days and avg_daily delivery by churn')\n",
    "\n",
    "# Manual legend\n",
    "blue_patch = mpatches.Patch(color='blue', label='미이탈')\n",
    "orange_patch = mpatches.Patch(color='orange', label='이탈')\n",
    "plt.legend(handles=[blue_patch, orange_patch])\n",
    "\n",
    "# 저장할 디렉토리 생성\n",
    "#os.makedirs('graphs', exist_ok=True)  \n",
    "\n",
    "# 그래프를 파일로 저장\n",
    "#plt.savefig(\"graphs_bike/density_plot.png\")\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train, test set split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = train_test_split(data_filtered_both, test_size = 0.25, \n",
    "#                                        stratify = data_filtered_both['outcome'], random_state=1234)\n",
    "# X_train = train_set[['birth', 'delivery_method', 'insurance_type', 'is_recom', 'gender','active_days', 'avg_daily_delivery', 'avg_distance', 'avg_fee', 'avg_distance_1_to_3', 'avg_fee_1_to_3', 'join_period', 'from_join_to_first_able', 'from_first_able_to_start', 'working_period']]\n",
    "# y_train = train_set['outcome']\n",
    "# X_test =  test_set[['birth', 'delivery_method', 'insurance_type', 'is_recom', 'gender','active_days', 'avg_daily_delivery', 'avg_distance', 'avg_fee', 'avg_distance_1_to_3', 'avg_fee_1_to_3', 'join_period', 'from_join_to_first_able', 'from_first_able_to_start', 'working_period']]\n",
    "# y_test = test_set['outcome']\n",
    "\n",
    "# print(X_train.shape, X_test.shape)  \n",
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data_filtered_both, test_size=0.25, \n",
    "                                       stratify=data_filtered_both['outcome'], random_state=1234)\n",
    "\n",
    "le_delivery_method = LabelEncoder()\n",
    "le_insurance_type = LabelEncoder()\n",
    "le_gender = LabelEncoder()\n",
    "\n",
    "data_filtered_both['delivery_method_encoded'] = le_delivery_method.fit_transform(data_filtered_both['delivery_method'])\n",
    "data_filtered_both['insurance_type_encoded'] = le_insurance_type.fit_transform(data_filtered_both['insurance_type'])\n",
    "data_filtered_both['gender_encoded'] = le_gender.fit_transform(data_filtered_both['gender'])\n",
    "\n",
    "\n",
    "train_set['delivery_method_encoded'] = data_filtered_both.loc[train_set.index, 'delivery_method_encoded']\n",
    "train_set['insurance_type_encoded'] = data_filtered_both.loc[train_set.index, 'insurance_type_encoded']\n",
    "train_set['gender_encoded'] = data_filtered_both.loc[train_set.index, 'gender_encoded']\n",
    "\n",
    "test_set['delivery_method_encoded'] = data_filtered_both.loc[test_set.index, 'delivery_method_encoded']\n",
    "test_set['insurance_type_encoded'] = data_filtered_both.loc[test_set.index, 'insurance_type_encoded']\n",
    "test_set['gender_encoded'] = data_filtered_both.loc[test_set.index, 'gender_encoded']\n",
    "\n",
    "\n",
    "train_set.drop(['delivery_method', 'insurance_type', 'gender'], axis=1, inplace=True)\n",
    "test_set.drop(['delivery_method', 'insurance_type', 'gender'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X_train = train_set[['birth', 'delivery_method_encoded', 'insurance_type_encoded', 'is_recom', 'gender_encoded',\n",
    "                     'active_days', 'avg_daily_delivery', 'avg_distance', 'avg_fee', \n",
    "                     'avg_distance_1_to_3', 'avg_fee_1_to_3', 'join_period', \n",
    "                     'from_join_to_first_able', 'from_first_able_to_start']]\n",
    "\n",
    "y_train = train_set['outcome']\n",
    "\n",
    "X_test = test_set[['birth', 'delivery_method_encoded', 'insurance_type_encoded', 'is_recom', 'gender_encoded',\n",
    "                   'active_days', 'avg_daily_delivery', 'avg_distance', 'avg_fee', \n",
    "                   'avg_distance_1_to_3', 'avg_fee_1_to_3', 'join_period', \n",
    "                   'from_join_to_first_able', 'from_first_able_to_start']]\n",
    "\n",
    "y_test = test_set['outcome']\n",
    "\n",
    "\n",
    "delivery_method_mapping = dict(zip(le_delivery_method.classes_, le_delivery_method.transform(le_delivery_method.classes_)))\n",
    "insurance_type_mapping = dict(zip(le_insurance_type.classes_, le_insurance_type.transform(le_insurance_type.classes_)))\n",
    "gender_mapping = dict(zip(le_gender.classes_, le_gender.transform(le_gender.classes_)))\n",
    "\n",
    "print(\"delivery_method:\", delivery_method_mapping)\n",
    "print(\"insurance_type:\", insurance_type_mapping)\n",
    "print(\"gender:\", gender_mapping)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range = list(range(1, 11))  # 1부터 10까지의 깊이를 테스트\n",
    "cv_scores = []\n",
    "random.seed(2234)\n",
    "\n",
    "for depth in depth_range:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)  # 5-fold 교차 검증\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# 교차 검증 점수가 가장 높은 max_depth 값 찾기\n",
    "optimal_depth = depth_range[cv_scores.index(max(cv_scores))]\n",
    "print(f\"Optimal max_depth is {optimal_depth}\")\n",
    "\n",
    "# 최적의 max_depth 값으로 모델 학습\n",
    "clf = DecisionTreeClassifier(max_depth=optimal_depth)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델의 정확도 확인\n",
    "print(f\"Training Accuracy: {clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test Accuracy: {clf.score(X_test, y_test):.4f}\")\n",
    "\n",
    "feature_names = [col.replace('_encoded', '') for col in X_train.columns]\n",
    "\n",
    "# Decision Tree 시각화\n",
    "fig, ax = plt.subplots(figsize=(24, 8))\n",
    "tree.plot_tree(clf, filled=True, feature_names=feature_names, class_names=['0', '1'], rounded=True, fontsize=10)\n",
    "#plt.savefig(\"graphs_bike/dt tree 1.png\")\n",
    "plt.show()\n",
    "\n",
    "# 교차 검증 점수에 따른 max_depth 값의 변화를 그래프로 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_range, cv_scores, marker='o', linestyle='-')\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Mean CV Score\")\n",
    "plt.title(\"Mean CV Score vs. max_depth\")\n",
    "plt.grid(True)\n",
    "#plt.savefig(\"graphs_bike/cv_dt tree.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 중요도 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "for idx in sorted_indices:\n",
    "    print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 학습 \n",
    "dep_n = 2\n",
    "random.seed(24534)\n",
    "clf = DecisionTreeClassifier(max_depth = dep_n)  \n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# 모델의 정확도 확인\n",
    "print(f\"Training Accuracy: {clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Test Accuracy: {clf.score(X_test, y_test):.4f}\")\n",
    "\n",
    "# Decision Tree 시각화\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "tree.plot_tree(clf, filled=True, feature_names=['active_days', 'avg_daily_delivery'], class_names=['0', '1'], rounded=True, fontsize=10)\n",
    "#plt.savefig(\"graphs_is_not_recom_bike/DT tree.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. \b연관규칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# 데이터셋을 one-hot-encoding 형태로 변환\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apriori 알고리즘을 사용하여 빈번한 항목 집합을 찾습니다.\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# 연관 규칙을 추출합니다.\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# 이탈 여부와 관련된 규칙만 필터링합니다.\n",
    "churn_rules = rules[rules['consequents'].apply(lambda x: 'outcome' in x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
